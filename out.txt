"**NVIDIA on GitHub ✅ success**
> Workflow [19889498266](<https://github.com/gpu-mode/discord-cluster-manager/actions/runs/19889498266>) completed
> Downloading artifacts... done
> ❌ Benchmarking failed

Running on:
* GPU: `NVIDIA B200`
* CPU: `INTEL(R) XEON(R) PLATINUM 8570`
* Runtime: `CUDA`
* Platform: `Linux-6.8.0-51-generic-x86_64-with-glibc2.35`
* Torch: `2.9.1+cu130`


## Benchmarks:
```
❌ k: 16384; l: 1; m: 128; n: 7168; seed: 1111 failed testing:

mismatch found! custom implementation doesn't match reference: Number of mismatched elements: 917502 ERROR AT (0, 0, 0): 35328.0 inf ERROR AT (0, 1, 0): 20192.0 inf ERROR AT (0, 2, 0): 894.0 inf ERROR AT (0, 3, 0): 20688.0 inf ERROR AT (0, 4, 0): 25328.0 inf ... and 917497 more mismatched elements.

❌ k: 7168; l: 1; m: 128; n: 4096; seed: 1111 failed testing:

mismatch found! custom implementation doesn't match reference: Number of mismatched elements: 524288 ERROR AT (0, 0, 0): 14424.0 inf ERROR AT (0, 1, 0): 14504.0 inf ERROR AT (0, 2, 0): 1384.0 inf ERROR AT (0, 3, 0): 16880.0 inf ERROR AT (0, 4, 0): 9336.0 inf ... and 524283 more mismatched elements.

❌ k: 2048; l: 1; m: 128; n: 7168; seed: 1111 failed testing:

mismatch found! custom implementation doesn't match reference: Number of mismatched elements: 917504 ERROR AT (0, 0, 0): -4428.0 19632.0 ERROR AT (0, 1, 0): 914.0 23456.0 ERROR AT (0, 2, 0): -976.0 23392.0 ERROR AT (0, 3, 0): 3300.0 18768.0 ERROR AT (0, 4, 0): -2308.0 19872.0 ... and 917499 more mismatched elements.
```

## Program stdout:
```
[dbg] A shape/stride/dtype: torch.Size([128, 8192, 1]) (8192, 1, 1048576) torch.float4_e2m1fn_x2
[dbg] B shape/stride/dtype: torch.Size([7168, 8192, 1]) (8192, 1, 58720256) torch.float4_e2m1fn_x2
[dbg] SFA shape/stride/dtype: torch.Size([128, 1024, 1]) (1024, 1, 131072) torch.float8_e4m3fn
[dbg] SFB shape/stride/dtype: torch.Size([7168, 1024, 1]) (1024, 1, 7340032) torch.float8_e4m3fn
[dbg] SFA[0,0:4,0]: [-1.0, -3.0, -3.0, 0.0]
[dbg] SFB[0,0:4,0]: [-2.0, 1.0, -1.0, 1.0]
[dbg] SFA_perm shape/dtype: torch.Size([32, 4, 1, 4, 256, 1]) torch.float8_e4m3fn
[dbg] SFA_perm[0,0,0,0,0,0]: -1.0
[dbg] SFB_perm shape/dtype: torch.Size([32, 4, 56, 4, 256, 1]) torch.float8_e4m3fn
[dbg] SFB_perm[0,0,0,0,0,0]: -2.0```"